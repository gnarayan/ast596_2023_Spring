{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (Due Feb. 10, 2023 at Noon) \n",
    "\n",
    "Submit your solution notebook in your directory via github PR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (50 pts)\n",
    "\n",
    "###  Fitting a Line using a Maximum Likelihood Estimator\n",
    "\n",
    "Last week, you implcitly fitted straight lines with methods of moments estimators (i.e. sample mean and variance) and L-estimators (median and IQR). Generally though, we want some kind of uncertainty estimate for our models, and therefore M-estimators and maximum likelihood estimators in particular are useful.\n",
    "\n",
    "Assume the scatter in our measurements (the residuals) is generated by a gaussian process i.e.:\n",
    "\n",
    ">$ y_i = a x_i + b + r_i $\n",
    "\n",
    "where $r_i$ is drawn from $N(0, \\sigma)$. Here, $\\sigma$ is the error the measurement induces.\n",
    "\n",
    "To use an M-estimator/MLE, you have to specify the likelihood function. First, the probability $p(y_i|x_i, M(a, b), \\sigma)$ that a particular point $y_i$ would be measured is just the normal distribution:\n",
    "\n",
    ">$ p(y_i|x_i, M(a, b), \\sigma) = N(y_i - M(x)|\\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(y_i - M(x_i))^2}{2 \\sigma^2} \\right) $.\n",
    "\n",
    "Given what we discussed in class, we can write down the $\\ln L$\n",
    "\n",
    ">$ \\ln L(a, b) = constant - \\frac{1}{2 \\sigma^2} \\sum_{i=1}^N (y_i - M(x_i))^2 $\n",
    "\n",
    "This is the expression that we now minimize with respect to $a$ and $b$ to find ML estimators for those parameters. \n",
    "\n",
    "\n",
    "And as we discussed in class, this is equivalent to minimizing the sum of the squares or a _least-squares method_.\n",
    "\n",
    "## MLE with outliers\n",
    "\n",
    "Let's apply the MLE to data with uncertainties where these uncertainties include outliers. \n",
    "I've defined a dataset below:\n",
    "\n",
    "Your mission is to:\n",
    "\n",
    "- write a function that computes the squared loss, and incorporates the uncertainties on the measurements, $dy$ (10 pts)\n",
    "- Fit a line to the full sample by evaluating this likelihood on a grid of a, b (10 pts)\n",
    "- Use sigma-clipping or an L-estimator for outlier rejection and fit a line to the data with outliers rejected (10 pts) and make a QQ plot of the residuals (10 pts)\n",
    "- Define a new likelihood function that implements the Huber loss, also incorporating the measurement uncertainties $dy$ (10 pts)\n",
    "- Fit a new line to all of the data (no outlier rejection) with the new Huber likelihod, except now use scipy.optimize.fmin instead of a grid search, and you know the drill by now - QQ plot of the residuals (10 pts)\n",
    "\n",
    "Recommended reading: David Hogg, Jo Bovy, and Dustin Lang: \"Data analysis recipes: Fitting a model to data\", 2010: https://arxiv.org/abs/1008.4686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.optimize\n",
    "import statsmodels.api as sm\n",
    "from astroML.datasets import fetch_hogg2010test\n",
    "\n",
    "# this just makes plots a bit easier on my laptop - disable as needed\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Get data: this includes outliers\n",
    "data = fetch_hogg2010test()\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "dy = data['sigma_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "The demo data set for this part is the Wesenheit index of the OGLE-III fundamental-mode and first overtone classical Cepheids. \n",
    "\n",
    "These stars are awesome because you can use them to measure distances. Here's a nice [youtube video](https://www.youtube.com/watch?v=iyisAjHdhas) on these stars.\n",
    "\n",
    "You'll try to estimate their period-luminosity relationship. \n",
    "\n",
    "The Wesenheit index is defined as `W = I - 1.55(V - I)`, and its main advantage over using simply the I or V photometry is that it is insensitive to extinction. It is denoted by 'W' among the data columns. \n",
    "\n",
    "Other columns are 'name', the identifier of the star; 'RA0' (in decimal hours) and 'Decl0' (in decimal degrees), celestial coordinates; 'Mode', the mode of the Cepheid ('F' indicates fundamental-mode, '1' indicates first overtone star); 'Cloud', indicating which Magellanic Cloud the star belongs to; 'logP1', the base-10 logarithm of the period in days; 'VI', the colour V-I.\n",
    "\n",
    "\n",
    "Split the data into LMC and SMC, and then again by mode F and 1, and plot the `W` on the y-axis vs `log(P1)` on x.\n",
    "Fit or estimate straight lines to each of the four samples using your solution to Problem 1. (10 pts)\n",
    "\n",
    "Compute the residuals of each sample to it's respective line. Do these residuals look like a normal distribution? If not, speculate on why (WATCH THE YOUTUBE VIDEO!) (10 pts)\n",
    "\n",
    "Plot the residuals color coded by if they are positive or negative vs RA and Dec (just like a Hess diagram in Problem 1). (15 pts)\n",
    "\n",
    "Finally, plot the residuals against the fitted `W` values, and just to anticipate the next homework assignment, also plot `log(P1) vs V-I`. Comment on what you are seeing. (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fds]",
   "language": "python",
   "name": "conda-env-fds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
