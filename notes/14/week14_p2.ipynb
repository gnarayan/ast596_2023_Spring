{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUjZTQVbmI-4"
   },
   "source": [
    "# Week 14, ASTR 596: Fundamentals of Data Science\n",
    "\n",
    "\n",
    "## Classification with a Multi-layer Perceptron (MLP)\n",
    "#### Shamelessly ripped off from Ashley Villar, who gets all the credit\n",
    "\n",
    "### Gautham Narayan \n",
    "\n",
    "##### <gsn@illinois.edu>\n",
    "\n",
    "Here, we will learn how to use one of the most common modules for building neural networks: Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZVxCOpuxNFp",
    "outputId": "4cc62ac2-f3bc-47e0-e2ed-152df179da4e"
   },
   "outputs": [],
   "source": [
    "# Run this to install some packages\n",
    "!pip install astronn torch tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZVxCOpuxNFp",
    "outputId": "4cc62ac2-f3bc-47e0-e2ed-152df179da4e"
   },
   "outputs": [],
   "source": [
    "# Run this \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# GN - deal with a stupid astroNN error\n",
    "import ssl \n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZVxCOpuxNFp",
    "outputId": "4cc62ac2-f3bc-47e0-e2ed-152df179da4e"
   },
   "source": [
    "## A few notes on Pytorch syntax\n",
    "\n",
    "Pytorch datatype summary: The model expects a single precision input. You can change the type of a tensor with `tensor_name.type(`), where tensor_name is the name of your tensor and type is the `dtype`. For typecasting into single precision floating points, use `float()`. A numpy array is typecasted with `array_name.astype(type)`. For single precision, the type should be `np.float32`. Before we analyze tensors we often want to convert them to numpy arrays with `tensor_name.numpy()`\n",
    "\n",
    "If pytorch has been tracking operations that resulted in the current tensor value, you need to detach the tensor from the graph (meaning you want to ignore things like its derivative) before you can transform it into a numpy array: `tensor_name.detach()`. Scalars can be detached with `scalar.item()`\n",
    "\n",
    "Pytorch allows you to easily use your CPU or GPU; however, we are not using this feature. If you tensor is currently on the GPU, you can bring it onto the CPU with `tensor_name.cpu()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHiDLvC7SvGR"
   },
   "source": [
    "# Problem 1: Understanding the Data\n",
    "\n",
    "For this problem set, we will use the Galaxy10 dataset made available via the astroNN module. This dataset is made up of 17736 images of galaxies which have been labelled by hand. See this [link](https://astronn.readthedocs.io/en/latest/galaxy10.html) for more information. \n",
    "\n",
    "First we will visualize our data.\n",
    "\n",
    "**Problem 1a** Show one example of each class as an image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vH8FF-l0TxXz",
    "outputId": "a9a130c7-9c72-43cf-fec5-766821517fd8"
   },
   "outputs": [],
   "source": [
    "from astroNN.datasets import load_galaxy10\n",
    "from astroNN.datasets.galaxy10 import galaxy10cls_lookup\n",
    "\n",
    "#helpful functions:\n",
    "#Load the images and labels as numbers\n",
    "images, labels_original = load_galaxy10()\n",
    "\n",
    "#convert numbers to a string\n",
    "galaxy10cls_lookup(labels_original[0])\n",
    "\n",
    "# Plot an example image from each class\n",
    "#### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dghsBXI3VXcY"
   },
   "source": [
    "**Problem 1b** Make a histogram showing the fraction of each class\n",
    "\n",
    "Keep only the top two classes (i.e., the classes with the most galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "PoClh9kFVV5Y",
    "outputId": "4eb788dc-83eb-4e89-93c6-d36f4c8b835b"
   },
   "outputs": [],
   "source": [
    "# make a histogram of the fraction of each class \n",
    "#### YOUR CODE HERE\n",
    "\n",
    "#Only work with 1 and 2\n",
    "#### YOUR CODE HERE\n",
    "\n",
    "# How many total galaxies are in class 1 + 2\n",
    "#### YOUR CODE HERE - one line\n",
    "\n",
    "# what is the shape of the images array\n",
    "#### YOUR CODE HERE - one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcZOURvbWWZt"
   },
   "source": [
    "This next block of code converts the data to a format which is more compatible with our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdTlL1sTmRbe"
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# we one-hot encode (see last lecture) the labels - this is just to make the labels work with torch\n",
    "labels_top_two_one_hot = F.one_hot(torch.tensor(labels_top_two - np.min(labels_top_two)).long(), num_classes=2)\n",
    "\n",
    "# convert the images to \"Tensor\" objects for torch, and make sure everything is a float\n",
    "images_top_two = torch.tensor(images_top_two).float()\n",
    "labels_top_two_one_hot = labels_top_two_one_hot.float()\n",
    "\n",
    "# we're going to flatten the images for our MLP - i.e. make a 2D image 1D \n",
    "# this won't matter in this toy problem, but might for more complex problems\n",
    "# it does have the great advantage of making your problem faster\n",
    "\n",
    "images_top_two_flat = #### YOUR CODE HERE - one line\n",
    "\n",
    "# if the imaages are 69x69x3 channels what's the flattened image size?\n",
    "#### YOUR CODE HERE - one line\n",
    "\n",
    "# Normalize the flux of the images here\n",
    "# this is standard - subtract mean, divide by standard deviation\n",
    "# to evaluate the mean and standard deviation though, use torch instead of numpy, since we've converted\n",
    "# to a tensor already\n",
    "\n",
    "#### YOUR CODE HERE - one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgkfExBpZA_X"
   },
   "source": [
    "**Problem 1c** Split the data into a training and test set (66/33 split) using the train_test_split function from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVCTXBKdrCVn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#### YOUR CODE HERE - one line\n",
    "\n",
    "# given the size you computed for the images above, and the number of total objects you have in class 1 and 2, \n",
    "# what do you expect for the size of the resulting tensor?\n",
    "\n",
    "#### YOUR CODE HERE - one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaKITO-mDuS4",
    "outputId": "7c8d8392-aaa5-45fc-f0eb-f8f3d28f2eec"
   },
   "outputs": [],
   "source": [
    "# verify that your images_train is the size you expect\n",
    "#### YOUR CODE HERE - ONE LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaKITO-mDuS4",
    "outputId": "7c8d8392-aaa5-45fc-f0eb-f8f3d28f2eec"
   },
   "outputs": [],
   "source": [
    "# and quickly plot the training data to see how it's structured now \n",
    "\n",
    "#### YOUR CODE HERE - ONE LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIAYeSPhZbQy"
   },
   "source": [
    "The next cell will outline how one can make a MLP with pytorch. \n",
    "\n",
    "**Problem 2a** Talk to a partner about how this code works, line by line. Add another hidden layer which is the same size as the first hidden layer.\n",
    "\n",
    "This should help:\n",
    "https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1VUC-2inrVD"
   },
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "      # this defines the model\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(MLP, self).__init__()\n",
    "            print(input_size,hidden_size)\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.hiddenlayer = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.outputlayer = torch.nn.Linear(self.hidden_size, 2)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            self.softmax = torch.nn.Softmax()\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            layer1 = self.hiddenlayer(x)\n",
    "            activation = self.sigmoid(layer1)\n",
    "            layer2 = self.outputlayer(activation)\n",
    "            \n",
    "            #### YOUR CODE TO ADD ANOTHER LAYER HERE\n",
    "            # You need an activation function - it can be the same as the one you used in layer1\n",
    "            # and an outputlayer \n",
    "            activation2 = \n",
    "            layer3 = \n",
    "            \n",
    "            # and finally something non-linear again to get the outputlayer you just created\n",
    "            # into your network's output\n",
    "            output = #### YOUR CODE HERE \n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbDKkusZZ3D8"
   },
   "source": [
    "The next block of code will show how one can train the model for 100 epochs. Note that we use the *binary cross-entropy* as our objective function and *stochastic gradient descent* as our optimization method.\n",
    "\n",
    "**Problem 2b** Edit the code so that the function plots the loss for the training and test loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AT8vw_GnxL8F"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(training_data,training_labels, test_data,test_labels, model):\n",
    "    # define the optimization\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.007,momentum=0.9)\n",
    "    for epoch in range(100):\n",
    "        # clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # compute the model output\n",
    "        myoutput = model(training_data)\n",
    "        # calculate loss\n",
    "        loss = criterion(myoutput, training_labels)\n",
    "        # credit assignment\n",
    "        loss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #### YOUR CODE HERE\n",
    "        # first evaluate the model on the test data\n",
    "        output_test = #### YOUR CODE HERE - one line\n",
    "        \n",
    "        # next compute the loss (in this case the binary cross-entropy) given the predicted output and the \n",
    "        # test labels\n",
    "        loss_test = #### YOUR CODE HERE - one line\n",
    "        \n",
    "        # finally plot the loss for the training and test set (black and red)\n",
    "        # the loss is a tensor, so see the note at the top befor eyou convert it to a numpy object \n",
    "        #### YOUR CODE HERE\n",
    "        \n",
    "        # here's a hint - this is going to print the loss at each epoch\n",
    "        print(epoch,loss.detach().numpy())\n",
    "    fig.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E11xxIMWbEz2"
   },
   "source": [
    "The next block trains the code, assuming a hidden layer size of 100 neurons.\n",
    "\n",
    "**Problem 2c** Change the learning rate `lr` to minimize the cross entropy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HET50GP4bEJi",
    "outputId": "6e361c90-daca-4d73-b736-e2464c269f7d"
   },
   "outputs": [],
   "source": [
    "model = MLP(np.shape(images_train[0])[0],100)\n",
    "train_model(images_train, labels_train, images_test, labels_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suh_J0qWbOFV"
   },
   "source": [
    "Write a function called `evaluate_model` which takes the image data, labels and model as input, and the accuracy as output. you can use the `accuracy_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XM7S2spqSBFq",
    "outputId": "4e6a85d6-dd99-440c-a81a-ef4d831d4414"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(data,labels, model):\n",
    "    #### YOUR CODE HERE\n",
    "    return(acc)\n",
    "\n",
    "# evaluate the model\n",
    "acc = evaluate_model(images_test,labels_test, model)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ_KFvIUj-sz"
   },
   "source": [
    "**Problem 2d** make a confusion matrix for the test set - you can use the `confusion_matrix` and `ConfusionMatrixDisplay` we imported from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "OrnvQDHhkE91",
    "outputId": "e266153e-ccad-4dbb-edfa-a40478ff00fd"
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the test images\n",
    "#### YOUR CODE HERE - one line\n",
    "\n",
    "# convert your predictions back to a numpy object\n",
    "#### YOUR CODE HERE - one line\n",
    "\n",
    "# you can use numpy's argmax with an axis argument to get the maximum prediction for each row/image\n",
    "#### YOUR CODE HERE - one line each for truth and prediction\n",
    "# I'm calling the variables truth and best_class\n",
    "\n",
    "# the confusion_matrix object just takes truth and prediction as arguments\n",
    "cm = confusion_matrix(truth, best_class)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A59krpL_iPB-"
   },
   "source": [
    "**Challenge Problem 3** Add a third class to your classifier and begin accounting for uneven classes. There are several steps to this:\n",
    "\n",
    "1. Edit the neural network to output 3 classes\n",
    "2. Change the criterion to a *custom criterion* function, such that the entropy of each class is weighted by the inverse fraction of each class size (e.g., if the galaxy class breakdowns are 1:2:3, the weights would be 6:3:2).\n",
    "\n",
    "This is basically copy and paste all of the above with light modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4amk25yj9J9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LO3DD_F9s9RW",
    "outputId": "86798a8e-d401-4d73-95ba-af56c9a1ab92"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNuI3wjLsumd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WfBvtYRXtWwf",
    "outputId": "811da629-325c-43cb-f9dd-67a1660d9240"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqNDuXS6tbxr",
    "outputId": "19889b33-5425-4cbd-ae4c-1776ca8efbad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "QvmK26rOt2Wi",
    "outputId": "8e6480f1-bafd-4692-cc12-355dca4a0e5e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeeplearningSolutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
